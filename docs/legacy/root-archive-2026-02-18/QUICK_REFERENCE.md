# âš¡ REFERENCIA RÃPIDA - GestiqCloud IA

## ğŸš€ Inicio RÃ¡pido (10 min)

```bash
# 1. Instalar Ollama
curl https://ollama.ai/install.sh | sh
ollama pull llama3.1:8b
ollama serve

# 2. Configurar
echo "OLLAMA_URL=http://localhost:11434" >> apps/backend/.env

# 3. Crear tablas
cd apps/backend && alembic upgrade head

# 4. Usar
curl http://localhost:8000/api/v1/health/ai
```

---

## ğŸ’» Uso en CÃ³digo

### Simple (sin logging)
```python
response = await AIService.query(
    task=AITask.ANALYSIS,
    prompt="Tu pregunta aquÃ­"
)
```

### Con logging (recomendado)
```python
response = await AIService.query(
    task=AITask.ANALYSIS,
    prompt="Tu pregunta aquÃ­",
    db=session,
    module="copilot"
)
```

### Con todas las opciones
```python
response = await AIService.query(
    task=AITask.CLASSIFICATION,
    prompt="Clasifica: ...",
    temperature=0.3,
    max_tokens=500,
    db=session,
    module="imports",
    user_id=user.id,
    enable_recovery=True
)
```

---

## ğŸ“Š Endpoints de Logs

```bash
# Logs recientes
curl http://localhost:8000/api/v1/ai/logs/recent?limit=20

# EstadÃ­sticas
curl http://localhost:8000/api/v1/ai/logs/statistics?hours=24

# Performance de proveedores
curl http://localhost:8000/api/v1/ai/logs/providers

# Top errores
curl http://localhost:8000/api/v1/ai/logs/errors/top

# AnÃ¡lisis completo
curl http://localhost:8000/api/v1/ai/logs/analysis/summary

# Sugerencias de fix
curl -X POST "http://localhost:8000/api/v1/ai/logs/errors/TIMEOUT/fix?error_message=timeout"
```

---

## ğŸ¯ Tipos de Tareas

```python
from app.services.ai import AITask

AITask.CLASSIFICATION    # Clasificar documentos
AITask.ANALYSIS         # Analizar datos
AITask.GENERATION       # Generar documentos
AITask.SUGGESTION       # Sugerencias
AITask.CHAT            # ConversaciÃ³n
AITask.EXTRACTION      # ExtracciÃ³n de datos
```

---

## ğŸ“ Archivos Importantes

| Archivo | Para... |
|---------|---------|
| IA_IMPLEMENTATION_SUMMARY.md | Entender quÃ© es |
| SETUP_AI_LOCAL.md | Setup Ollama |
| AI_INTEGRATION_GUIDE.md | Ejemplos de uso |
| ERROR_HANDLING_AND_RECOVERY.md | Logging y recovery |
| INTEGRATION_CHECKLIST.md | Pasos de integraciÃ³n |

---

## ğŸ” Debugging

```bash
# Ver si Ollama estÃ¡ corriendo
curl http://localhost:11434/api/tags

# Health check de IA
curl http://localhost:8000/api/v1/health/ai

# Ver logs con debug
LOG_LEVEL=DEBUG uvicorn app.main:app

# Ver logs recientes
curl http://localhost:8000/api/v1/ai/logs/recent?limit=5
```

---

## âš™ï¸ ConfiguraciÃ³n BÃ¡sica

```bash
# Desarrollo
ENVIRONMENT=development
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# ProducciÃ³n
ENVIRONMENT=production
OVHCLOUD_API_KEY=xxx
OVHCLOUD_API_SECRET=xxx
OPENAI_API_KEY=xxx
```

---

## ğŸ†˜ Problemas Comunes

| Problema | SoluciÃ³n |
|----------|----------|
| "Connection refused" | Verificar `ollama serve` corre |
| "No providers available" | Verificar OLLAMA_URL en .env |
| "Table does not exist" | Ejecutar `alembic upgrade head` |
| "ImportError ai_logs" | Verificar routers importados en main.py |
| "Slow responses" | Usar modelo mÃ¡s pequeÃ±o (mistral:7b) |

---

## ğŸ“ˆ MÃ©tricas Clave

```bash
# Error rate Ãºltimas 24h
curl "http://localhost:8000/api/v1/ai/logs/statistics?hours=24"
# â†’ Buscar "error_rate"

# Proveedor mÃ¡s rÃ¡pido
curl "http://localhost:8000/api/v1/ai/logs/providers?hours=24"
# â†’ Buscar "avg_time_ms" mÃ¡s bajo

# Requests mÃ¡s lentos
curl "http://localhost:8000/api/v1/ai/logs/requests/slow?limit=5"
```

---

## ğŸ”„ Estrategias de RecuperaciÃ³n

1. **RetryStrategy** - Reintenta 2-3 veces con backoff
2. **SimplifyStrategy** - Reduce prompt si es muy largo
3. **FallbackStrategy** - Cambia a otro proveedor
4. **CacheStrategy** - (futuro) Usa cachÃ©

AutomÃ¡ticas cuando `enable_recovery=True` (por defecto)

---

## ğŸ“¦ Estructura de Directorios

```
apps/backend/app/
â”œâ”€â”€ services/ai/              # â† Nuevo mÃ³dulo IA
â”‚   â”œâ”€â”€ base.py              # Interfaces
â”‚   â”œâ”€â”€ service.py           # API unificada
â”‚   â”œâ”€â”€ factory.py           # Factory
â”‚   â”œâ”€â”€ logging.py           # Logger
â”‚   â”œâ”€â”€ recovery.py          # RecuperaciÃ³n
â”‚   â””â”€â”€ providers/           # Proveedores
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ai_log.py            # â† Modelos BD
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ ai_health.py         # â† Health checks
â”‚   â””â”€â”€ ai_logs.py           # â† Endpoints logs
```

---

## âœ… Checklist RÃ¡pido

```
Setup:
  [ ] Ollama instalado y corriendo
  [ ] .env configurado
  [ ] Tablas BD creadas
  [ ] Routers importados

Uso:
  [ ] Pasado db=session a AIService.query()
  [ ] Health check funciona
  [ ] Logs se crean en BD

IntegraciÃ³n:
  [ ] Copilot integrado
  [ ] Tests funcionando
  [ ] Logs se ven en /api/v1/ai/logs
```

---

## ğŸ“ Ejemplos PrÃ¡cticos

### Clasificar documento
```python
result = await AIService.classify_document(
    document_content="FACTURA #001...",
    expected_types=["invoice", "order", "receipt"],
    confidence_threshold=0.75
)
print(f"Tipo: {result['type']}, Confianza: {result['confidence']:.1%}")
```

### Analizar incidencia
```python
analysis = await AIService.analyze_incident(
    incident_type="database_error",
    description="Connection timeout",
    additional_context={"frequency": "intermittent"}
)
print(f"Causa: {analysis['root_cause']}")
print(f"Acciones: {analysis['recommended_actions']}")
```

### Generar sugerencia
```python
suggestion = await AIService.generate_suggestion(
    context="Stock bajo de producto XYZ",
    suggestion_type="inventory"
)
print(suggestion)
```

---

## ğŸ”— Links RÃ¡pidos

- Ollama: https://ollama.ai
- OVHCloud AI: https://manager.eu.ovhcloud.com
- OpenAI: https://api.openai.com
- DocumentaciÃ³n completa: Revisar archivos .md en raÃ­z

---

## ğŸ“ Soporte

- **InstalaciÃ³n**: SETUP_AI_LOCAL.md
- **IntegraciÃ³n**: INTEGRATION_CHECKLIST.md
- **Uso**: AI_INTEGRATION_GUIDE.md
- **Errores**: ERROR_HANDLING_AND_RECOVERY.md
- **Tablas**: MIGRATION_AI_LOGGING.md

---

**Â¡Listo para empezar!** ğŸš€
